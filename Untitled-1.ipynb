{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['👹']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "\n",
    "# Veri setini hazırla\n",
    "ozetler = ['Bir grup cesur insan, karanlık bir ormanda yaşayan bir canavara karşı mücadele eder.', 'Bir adam, sevdiği kadını kurtarmak için zaman yolculuğuna çıkar.', 'Bir bilim adamı, uzaylılarla dolu bir gezegene düşer ve hayatta kalmak için mücadele eder.']\n",
    "emojiler = ['👹', '⏰', '👽']\n",
    "df = pd.DataFrame({'Özet': ozetler, 'Emoji': emojiler})\n",
    "\n",
    "# Öznitelikleri ve hedef değişkeni belirle\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['Özet'])\n",
    "y = df['Emoji']\n",
    "\n",
    "# Modeli oluştur ve eğit\n",
    "model = MultinomialNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Yeni bir film özeti ile emoji tahmini yap\n",
    "new_ozet = 'Selamlar, bu bir deneme mesajıdır.'\n",
    "X_new = cv.transform([new_ozet])\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Tahmin edilen emojiyi yazdır\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['🔫']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "\n",
    "# Veri setini hazırla\n",
    "ozetler = [['live', 'two', 'mob', 'hitmen', 'boxer', 'gangster', 'wife', 'pair', 'diner', 'bandits', 'intertwine', 'four', 'tales', 'violence', 'redemption'],\n",
    "           ['live', 'two', 'mob', 'hitmen', 'boxer', 'gangster', 'wife', 'pair', 'diner', 'bandits', 'intertwine', 'four', 'tales', 'violence', 'redemption'],\n",
    "           ['gandalf', 'aragorn', 'lead', 'world', 'men', 'saurons', 'army', 'draw', 'gaze', 'frodo', 'sam', 'approach', 'mount', 'doom', 'one', 'ring'],\n",
    "           ['germanoccupied', 'poland', 'world', 'war', 'ii', 'industrialist', 'oskar', 'schindler', 'gradually', 'become', 'concern', 'jewish', 'workforce', 'witness', 'persecution', 'nazis']]\n",
    "emojiler = ['🔫','🥊','🧙‍♂️','🎥']\n",
    "df = pd.DataFrame({'Özet': ozetler, 'Emoji': emojiler})\n",
    "\n",
    "# Öznitelikleri ve hedef değişkeni belirle\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['Özet'].apply(lambda x: ' '.join(x)))\n",
    "y = df['Emoji']\n",
    "\n",
    "# Modeli oluştur ve eğit\n",
    "model = MultinomialNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# Yeni bir film özeti ile emoji tahmini yap\n",
    "new_ozet = [['live', 'poland', 'selamlar']]\n",
    "X_new = cv.transform([' '.join(new_ozet[0])])\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Tahmin edilen emojiyi yazdır\n",
    "print(y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Örnek 1:\n",
      "\tSınıf: 🔫, Olasılık: 0.2897\n",
      "\tSınıf: 🥊, Olasılık: 0.2897\n",
      "\tSınıf: 🎥, Olasılık: 0.2804\n",
      "\tSınıf: 🧙‍♂️, Olasılık: 0.1402\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Yeni bir film özeti ile sınıf olasılıklarını tahmin et\n",
    "new_ozet = [['live', 'poland', 'selamlar']]\n",
    "X_new = cv.transform([' '.join(new_ozet[0])])\n",
    "y_proba = model.predict_proba(X_new)\n",
    "\n",
    "# Her bir sınıf için olasılıkları sırala\n",
    "top_5_idx = np.argsort(-y_proba, axis=1)[:, :5]\n",
    "top_5_proba = np.array([y_proba[i, idx] for i, idx in enumerate(top_5_idx)])\n",
    "top_5_classes = np.array([model.classes_[idx] for idx in top_5_idx])\n",
    "\n",
    "# En yüksek 5 olasılıklı sınıfları ve ilgili olasılıkları yazdır\n",
    "for i in range(len(top_5_classes)):\n",
    "    print(f\"Örnek {i+1}:\")\n",
    "    for j in range(len(top_5_classes[i])):\n",
    "        print(f\"\\tSınıf: {top_5_classes[i][j]}, Olasılık: {top_5_proba[i][j]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Özet Emoji\n",
      "0  Bir grup cesur insan, karanlık bir ormanda yaş...     👹\n",
      "1  Bir adam, sevdiği kadını kurtarmak için zaman ...     ⏰\n",
      "2  Bir bilim adamı, uzaylılarla dolu bir gezegene...     👽\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Film özetleri ve uygun emojiler\n",
    "ozetler = ['Bir grup cesur insan, karanlık bir ormanda yaşayan bir canavara karşı mücadele eder.', 'Bir adam, sevdiği kadını kurtarmak için zaman yolculuğuna çıkar.', 'Bir bilim adamı, uzaylılarla dolu bir gezegene düşer ve hayatta kalmak için mücadele eder.']\n",
    "emojiler = ['👹', '⏰', '👽']\n",
    "\n",
    "# Veri setini oluştur\n",
    "df = pd.DataFrame({'Özet': ozetler, 'Emoji': emojiler})\n",
    "\n",
    "# Veri setini yazdır\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mustafayanar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mustafayanar/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[two, imprison, men, bond, number, years, find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[organize, crime, dynastys, age, patriarch, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[menace, know, joker, wreak, havoc, chaos, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[early, life, career, vito, corleone, 1920s, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jury, holdout, attempt, prevent, miscarriage,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Overview\n",
       "0  [two, imprison, men, bond, number, years, find...\n",
       "1  [organize, crime, dynastys, age, patriarch, tr...\n",
       "2  [menace, know, joker, wreak, havoc, chaos, peo...\n",
       "3  [early, life, career, vito, corleone, 1920s, n...\n",
       "4  [jury, holdout, attempt, prevent, miscarriage,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Küçük harfe çevirme\n",
    "df[\"Overview\"] = df[\"Overview\"].str.lower()\n",
    "\n",
    "# Noktalama işaretlerini kaldırma\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# Stop word'leri çıkarma\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: \" \".join(word for word in x.split() if word not in stop_words))\n",
    "\n",
    "# Tokenizasyon\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: x.split())\n",
    "\n",
    "# Lemmatization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: [lemmatizer.lemmatize(word, pos='v') for word in x])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv(\"imdb_overviews_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A jury holdout attempts to prevent a miscarria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Overview\n",
       "0  Two imprisoned men bond over a number of years...\n",
       "1  An organized crime dynasty's aging patriarch t...\n",
       "2  When the menace known as the Joker wreaks havo...\n",
       "3  The early life and career of Vito Corleone in ...\n",
       "4  A jury holdout attempts to prevent a miscarria..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"imdb_overviews.csv\", delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasını yükle\n",
    "df = pd.read_csv(\"imdb_top_1000.csv\")\n",
    "\n",
    "# Sadece \"Overview\" sütununu seç\n",
    "df = df[[\"Overview\"]]\n",
    "\n",
    "# Yeni dosyayı kaydet\n",
    "df.to_csv(\"imdb_overviews.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧑‍🌾,🏡,🔢,👥,👣,🛣️,🧨,💪,🏆,🌍,🌑\n",
    "elimde böyle emojilerden oluşan bir array var ve şöyle bir yazı var\n",
    "\"['meek', 'hobbit', 'shire', 'eight', 'companion', 'set', 'journey', 'destroy', 'powerful', 'one', 'ring', 'save', 'middleearth', 'dark', 'lord', 'sauron']\"\n",
    "bana emoji arrayi kadar satırlık 2 sütunlu bir dataframe oluşturur musun soldaki sutünda hep o yazı olacak şekilde bunun python kodunu istiyorum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emojis = ['🧑‍🌾', '🏡', '🔢', '👥', '👣', '🛣️', '🧨', '💪', '🏆', '🌍', '🌑']\n",
    "words = ['meek', 'hobbit', 'shire', 'eight', 'companion', 'set', 'journey', 'destroy', 'powerful', 'one', 'ring', 'save', 'middleearth', 'dark', 'lord', 'sauron']\n",
    "\n",
    "data = {'Emoji': emojis, 'Words': [\", \".join(words) for i in range(len(emojis))]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSV dosyasına ekle\n",
    "df.to_csv('deneme.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['🚀', '🌟', '🎂', '🦁']\n",
      "['two', 'imprison', 'men', 'bond', 'number', 'years', 'find', 'solace', 'eventual', 'redemption', 'act', 'common', 'decency']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "with open('input.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))[0]\n",
    "    words = [w.strip(\"' \") for w in data]\n",
    "\n",
    "emojis = []\n",
    "while True:\n",
    "    emoji_input = input(\"Lütfen bir emoji girin ('q' girerek çıkabilirsiniz): \")\n",
    "    if emoji_input.lower() == 'q':\n",
    "        break\n",
    "    emojis = ([c for c in emoji_input if c.isprintable() and c != \"'\" and c != \"[\" and c != \"]\" and c != \" \" and c != \",\"])\n",
    "# şimdilik tek satır için baktığım için forun dışına aldım\n",
    "print (emojis)\n",
    "print (words)\n",
    "data = {'Emoji': emojis, 'Words': [\", \".join(words) for i in range(len(emojis))]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSV dosyasına ekle\n",
    "df.to_csv('output.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['🚀', '🌟', '🎂', '🦁']\n"
     ]
    }
   ],
   "source": [
    "emojis_input = input(\"Lütfen bir emoji girin ('q' girerek çıkabilirsiniz): \")\n",
    "emojis = [c for c in emojis_input if c.isprintable() and c != \"'\" and c != \"[\" and c != \"]\" and c != \" \" and c != \",\"]\n",
    "print(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"'two'\"]]\n"
     ]
    }
   ],
   "source": [
    "words_df = pd.read_csv(\"input.csv\", header=None)\n",
    "words = [row[0].split(',') for index, row in words_df.iterrows()]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'imprison', 'men', 'bond', 'number', 'years', 'find', 'solace', 'eventual', 'redemption', 'act', 'common', 'decency']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('input.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))[0]\n",
    "    words = [w.strip(\"' \") for w in data]\n",
    "    print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sa', 'merhaba', 'selamlar']\n"
     ]
    }
   ],
   "source": [
    "sa = ['sa', 'merhaba', 'selamlar']\n",
    "print(sa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'imprison', 'men', 'bond', 'number', 'years', 'find', 'solace', 'eventual', 'redemption', 'act', 'common', 'decency']\n"
     ]
    }
   ],
   "source": [
    "data_str = \"two, imprison, men, bond, number, years, find, solace, eventual, redemption, act, common, decency\"\n",
    "data_arr = data_str.split(\", \")\n",
    "print(data_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
