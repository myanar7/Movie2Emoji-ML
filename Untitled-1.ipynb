{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ğŸ‘¹']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "\n",
    "# Veri setini hazÄ±rla\n",
    "ozetler = ['Bir grup cesur insan, karanlÄ±k bir ormanda yaÅŸayan bir canavara karÅŸÄ± mÃ¼cadele eder.', 'Bir adam, sevdiÄŸi kadÄ±nÄ± kurtarmak iÃ§in zaman yolculuÄŸuna Ã§Ä±kar.', 'Bir bilim adamÄ±, uzaylÄ±larla dolu bir gezegene dÃ¼ÅŸer ve hayatta kalmak iÃ§in mÃ¼cadele eder.']\n",
    "emojiler = ['ğŸ‘¹', 'â°', 'ğŸ‘½']\n",
    "df = pd.DataFrame({'Ã–zet': ozetler, 'Emoji': emojiler})\n",
    "\n",
    "# Ã–znitelikleri ve hedef deÄŸiÅŸkeni belirle\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['Ã–zet'])\n",
    "y = df['Emoji']\n",
    "\n",
    "# Modeli oluÅŸtur ve eÄŸit\n",
    "model = MultinomialNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Yeni bir film Ã¶zeti ile emoji tahmini yap\n",
    "new_ozet = 'Selamlar, bu bir deneme mesajÄ±dÄ±r.'\n",
    "X_new = cv.transform([new_ozet])\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Tahmin edilen emojiyi yazdÄ±r\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ğŸ”«']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "\n",
    "# Veri setini hazÄ±rla\n",
    "ozetler = [['live', 'two', 'mob', 'hitmen', 'boxer', 'gangster', 'wife', 'pair', 'diner', 'bandits', 'intertwine', 'four', 'tales', 'violence', 'redemption'],\n",
    "           ['live', 'two', 'mob', 'hitmen', 'boxer', 'gangster', 'wife', 'pair', 'diner', 'bandits', 'intertwine', 'four', 'tales', 'violence', 'redemption'],\n",
    "           ['gandalf', 'aragorn', 'lead', 'world', 'men', 'saurons', 'army', 'draw', 'gaze', 'frodo', 'sam', 'approach', 'mount', 'doom', 'one', 'ring'],\n",
    "           ['germanoccupied', 'poland', 'world', 'war', 'ii', 'industrialist', 'oskar', 'schindler', 'gradually', 'become', 'concern', 'jewish', 'workforce', 'witness', 'persecution', 'nazis']]\n",
    "emojiler = ['ğŸ”«','ğŸ¥Š','ğŸ§™â€â™‚ï¸','ğŸ¥']\n",
    "df = pd.DataFrame({'Ã–zet': ozetler, 'Emoji': emojiler})\n",
    "\n",
    "# Ã–znitelikleri ve hedef deÄŸiÅŸkeni belirle\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(df['Ã–zet'].apply(lambda x: ' '.join(x)))\n",
    "y = df['Emoji']\n",
    "\n",
    "# Modeli oluÅŸtur ve eÄŸit\n",
    "model = MultinomialNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# Yeni bir film Ã¶zeti ile emoji tahmini yap\n",
    "new_ozet = [['live', 'poland', 'selamlar']]\n",
    "X_new = cv.transform([' '.join(new_ozet[0])])\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Tahmin edilen emojiyi yazdÄ±r\n",
    "print(y_pred) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã–rnek 1:\n",
      "\tSÄ±nÄ±f: ğŸ”«, OlasÄ±lÄ±k: 0.2897\n",
      "\tSÄ±nÄ±f: ğŸ¥Š, OlasÄ±lÄ±k: 0.2897\n",
      "\tSÄ±nÄ±f: ğŸ¥, OlasÄ±lÄ±k: 0.2804\n",
      "\tSÄ±nÄ±f: ğŸ§™â€â™‚ï¸, OlasÄ±lÄ±k: 0.1402\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Yeni bir film Ã¶zeti ile sÄ±nÄ±f olasÄ±lÄ±klarÄ±nÄ± tahmin et\n",
    "new_ozet = [['live', 'poland', 'selamlar']]\n",
    "X_new = cv.transform([' '.join(new_ozet[0])])\n",
    "y_proba = model.predict_proba(X_new)\n",
    "\n",
    "# Her bir sÄ±nÄ±f iÃ§in olasÄ±lÄ±klarÄ± sÄ±rala\n",
    "top_5_idx = np.argsort(-y_proba, axis=1)[:, :5]\n",
    "top_5_proba = np.array([y_proba[i, idx] for i, idx in enumerate(top_5_idx)])\n",
    "top_5_classes = np.array([model.classes_[idx] for idx in top_5_idx])\n",
    "\n",
    "# En yÃ¼ksek 5 olasÄ±lÄ±klÄ± sÄ±nÄ±flarÄ± ve ilgili olasÄ±lÄ±klarÄ± yazdÄ±r\n",
    "for i in range(len(top_5_classes)):\n",
    "    print(f\"Ã–rnek {i+1}:\")\n",
    "    for j in range(len(top_5_classes[i])):\n",
    "        print(f\"\\tSÄ±nÄ±f: {top_5_classes[i][j]}, OlasÄ±lÄ±k: {top_5_proba[i][j]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Ã–zet Emoji\n",
      "0  Bir grup cesur insan, karanlÄ±k bir ormanda yaÅŸ...     ğŸ‘¹\n",
      "1  Bir adam, sevdiÄŸi kadÄ±nÄ± kurtarmak iÃ§in zaman ...     â°\n",
      "2  Bir bilim adamÄ±, uzaylÄ±larla dolu bir gezegene...     ğŸ‘½\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Film Ã¶zetleri ve uygun emojiler\n",
    "ozetler = ['Bir grup cesur insan, karanlÄ±k bir ormanda yaÅŸayan bir canavara karÅŸÄ± mÃ¼cadele eder.', 'Bir adam, sevdiÄŸi kadÄ±nÄ± kurtarmak iÃ§in zaman yolculuÄŸuna Ã§Ä±kar.', 'Bir bilim adamÄ±, uzaylÄ±larla dolu bir gezegene dÃ¼ÅŸer ve hayatta kalmak iÃ§in mÃ¼cadele eder.']\n",
    "emojiler = ['ğŸ‘¹', 'â°', 'ğŸ‘½']\n",
    "\n",
    "# Veri setini oluÅŸtur\n",
    "df = pd.DataFrame({'Ã–zet': ozetler, 'Emoji': emojiler})\n",
    "\n",
    "# Veri setini yazdÄ±r\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mustafayanar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mustafayanar/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[two, imprison, men, bond, number, years, find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[organize, crime, dynastys, age, patriarch, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[menace, know, joker, wreak, havoc, chaos, peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[early, life, career, vito, corleone, 1920s, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jury, holdout, attempt, prevent, miscarriage,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Overview\n",
       "0  [two, imprison, men, bond, number, years, find...\n",
       "1  [organize, crime, dynastys, age, patriarch, tr...\n",
       "2  [menace, know, joker, wreak, havoc, chaos, peo...\n",
       "3  [early, life, career, vito, corleone, 1920s, n...\n",
       "4  [jury, holdout, attempt, prevent, miscarriage,..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# KÃ¼Ã§Ã¼k harfe Ã§evirme\n",
    "df[\"Overview\"] = df[\"Overview\"].str.lower()\n",
    "\n",
    "# Noktalama iÅŸaretlerini kaldÄ±rma\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# Stop word'leri Ã§Ä±karma\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: \" \".join(word for word in x.split() if word not in stop_words))\n",
    "\n",
    "# Tokenizasyon\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: x.split())\n",
    "\n",
    "# Lemmatization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df[\"Overview\"] = df[\"Overview\"].apply(lambda x: [lemmatizer.lemmatize(word, pos='v') for word in x])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.to_csv(\"imdb_overviews_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two imprisoned men bond over a number of years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An organized crime dynasty's aging patriarch t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The early life and career of Vito Corleone in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A jury holdout attempts to prevent a miscarria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Overview\n",
       "0  Two imprisoned men bond over a number of years...\n",
       "1  An organized crime dynasty's aging patriarch t...\n",
       "2  When the menace known as the Joker wreaks havo...\n",
       "3  The early life and career of Vito Corleone in ...\n",
       "4  A jury holdout attempts to prevent a miscarria..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"imdb_overviews.csv\", delimiter=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV dosyasÄ±nÄ± yÃ¼kle\n",
    "df = pd.read_csv(\"imdb_top_1000.csv\")\n",
    "\n",
    "# Sadece \"Overview\" sÃ¼tununu seÃ§\n",
    "df = df[[\"Overview\"]]\n",
    "\n",
    "# Yeni dosyayÄ± kaydet\n",
    "df.to_csv(\"imdb_overviews.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ§‘â€ğŸŒ¾,ğŸ¡,ğŸ”¢,ğŸ‘¥,ğŸ‘£,ğŸ›£ï¸,ğŸ§¨,ğŸ’ª,ğŸ†,ğŸŒ,ğŸŒ‘\n",
    "elimde bÃ¶yle emojilerden oluÅŸan bir array var ve ÅŸÃ¶yle bir yazÄ± var\n",
    "\"['meek', 'hobbit', 'shire', 'eight', 'companion', 'set', 'journey', 'destroy', 'powerful', 'one', 'ring', 'save', 'middleearth', 'dark', 'lord', 'sauron']\"\n",
    "bana emoji arrayi kadar satÄ±rlÄ±k 2 sÃ¼tunlu bir dataframe oluÅŸturur musun soldaki sutÃ¼nda hep o yazÄ± olacak ÅŸekilde bunun python kodunu istiyorum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emojis = ['ğŸ§‘â€ğŸŒ¾', 'ğŸ¡', 'ğŸ”¢', 'ğŸ‘¥', 'ğŸ‘£', 'ğŸ›£ï¸', 'ğŸ§¨', 'ğŸ’ª', 'ğŸ†', 'ğŸŒ', 'ğŸŒ‘']\n",
    "words = ['meek', 'hobbit', 'shire', 'eight', 'companion', 'set', 'journey', 'destroy', 'powerful', 'one', 'ring', 'save', 'middleearth', 'dark', 'lord', 'sauron']\n",
    "\n",
    "data = {'Emoji': emojis, 'Words': [\", \".join(words) for i in range(len(emojis))]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSV dosyasÄ±na ekle\n",
    "df.to_csv('deneme.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ğŸš€', 'ğŸŒŸ', 'ğŸ‚', 'ğŸ¦']\n",
      "['two', 'imprison', 'men', 'bond', 'number', 'years', 'find', 'solace', 'eventual', 'redemption', 'act', 'common', 'decency']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "with open('input.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))[0]\n",
    "    words = [w.strip(\"' \") for w in data]\n",
    "\n",
    "emojis = []\n",
    "while True:\n",
    "    emoji_input = input(\"LÃ¼tfen bir emoji girin ('q' girerek Ã§Ä±kabilirsiniz): \")\n",
    "    if emoji_input.lower() == 'q':\n",
    "        break\n",
    "    emojis = ([c for c in emoji_input if c.isprintable() and c != \"'\" and c != \"[\" and c != \"]\" and c != \" \" and c != \",\"])\n",
    "# ÅŸimdilik tek satÄ±r iÃ§in baktÄ±ÄŸÄ±m iÃ§in forun dÄ±ÅŸÄ±na aldÄ±m\n",
    "print (emojis)\n",
    "print (words)\n",
    "data = {'Emoji': emojis, 'Words': [\", \".join(words) for i in range(len(emojis))]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# CSV dosyasÄ±na ekle\n",
    "df.to_csv('output.csv', mode='a', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ğŸš€', 'ğŸŒŸ', 'ğŸ‚', 'ğŸ¦']\n"
     ]
    }
   ],
   "source": [
    "emojis_input = input(\"LÃ¼tfen bir emoji girin ('q' girerek Ã§Ä±kabilirsiniz): \")\n",
    "emojis = [c for c in emojis_input if c.isprintable() and c != \"'\" and c != \"[\" and c != \"]\" and c != \" \" and c != \",\"]\n",
    "print(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"'two'\"]]\n"
     ]
    }
   ],
   "source": [
    "words_df = pd.read_csv(\"input.csv\", header=None)\n",
    "words = [row[0].split(',') for index, row in words_df.iterrows()]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'imprison', 'men', 'bond', 'number', 'years', 'find', 'solace', 'eventual', 'redemption', 'act', 'common', 'decency']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('input.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))[0]\n",
    "    words = [w.strip(\"' \") for w in data]\n",
    "    print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sa', 'merhaba', 'selamlar']\n"
     ]
    }
   ],
   "source": [
    "sa = ['sa', 'merhaba', 'selamlar']\n",
    "print(sa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['two', 'imprison', 'men', 'bond', 'number', 'years', 'find', 'solace', 'eventual', 'redemption', 'act', 'common', 'decency']\n"
     ]
    }
   ],
   "source": [
    "data_str = \"two, imprison, men, bond, number, years, find, solace, eventual, redemption, act, common, decency\"\n",
    "data_arr = data_str.split(\", \")\n",
    "print(data_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
