# Movie2Emoji-ML
This is a basic machine learning model to predict related emojis from movie summaries.


```
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Embedding, SpatialDropout1D, GlobalMaxPooling1D
from keras.optimizers import Adam
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
``` 
# Veri kÃ¼mesi oluÅŸturma

```
film_ozetleri = ["HÄ±zlÄ± ve Ã–fkeli serisi, arabalarla yapÄ±lan yarÄ±ÅŸlarÄ± konu alÄ±r.", "Kara ÅÃ¶valye, Batman'in Joker ile mÃ¼cadelesini anlatÄ±r.", "Harry Potter, Hogwarts bÃ¼yÃ¼cÃ¼lÃ¼k okulundaki maceralarÄ± konu alÄ±r.", "Baba filminde, aile iÃ§indeki gÃ¼Ã§ mÃ¼cadelesi iÅŸlenir.", "The Avengers, sÃ¼per kahramanlarÄ±n bir bir araya gelerek dÃ¼nyayÄ± kurtarmak iÃ§in mÃ¼cadelesini konu alÄ±r."]

emojiler = ['ğŸï¸', 'ğŸ¦‡', 'ğŸ§™â€â™‚ï¸', 'ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦', 'ğŸ¦¸â€â™‚ï¸']
```
# Film Ã¶zetleri ve emojileri birleÅŸtirerek veri kÃ¼mesi oluÅŸturma

```
veri = pd.DataFrame({'ozet': film_ozetleri,
'emoji': emojiler})

```

# Ã–zetleri belirteÃ§lere dÃ¶nÃ¼ÅŸtÃ¼rme ve belirteÃ§ vektÃ¶rlerini oluÅŸturma

```
tokenizer = Tokenizer()
tokenizer.fit_on_texts(veri['ozet'])
ozetler = tokenizer.texts_to_sequences(veri['ozet'])
ozetler = pad_sequences(ozetler)
```

# Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rma

```
X_train, X_test, y_train, y_test = train_test_split(ozetler, veri['emoji'], test_size=0.2, random_state=42)
```
# Yapay sinir aÄŸÄ± modeli oluÅŸturma

```
model = Sequential()
model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=X_train.shape[1]))
model.add(SpatialDropout1D(0.2))
model.add(GlobalMaxPooling1D())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(len(emojiler), activation='softmax'))
```
# Modeli derleme ve eÄŸitim
```
adam = Adam(learning_rate=0.01)
model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])
model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))
```
# Modeli deÄŸerlendirme

```
loss, accuracy = model.evaluate(X_test, y_test)
print("Test loss: {:.2f}, Test accuracy: {:.2f}%".format(loss, accuracy * 100))
```
# Tokenizer'Ä± oluÅŸturma

```
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)
```
# Kelimeleri sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rme

```
X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)
```

# EÄŸitim ve test verilerini aynÄ± boyuta getirme

```
X_train = pad_sequences(X_train, maxlen=max_len)
X_test = pad_sequences(X_test, maxlen=max_len)
```
# Modeli oluÅŸturma

```
model = Sequential()
model.add(Embedding(max_words, embedding_dim, input_length=max_len))
model.add(SpatialDropout1D(0.2))
model.add(GlobalMaxPooling1D())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))
```
# Modeli derleme

```
optimizer = Adam(learning_rate=learning_rate)
model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
```
# Modeli eÄŸitme

```
history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))
```
# Modelin performansÄ±nÄ± gÃ¶rselleÅŸtirme

```
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
```
# Modelin test verisi Ã¼zerindeki performansÄ±nÄ± hesaplama

```
score = model.evaluate(X_test, y_test, verbose=0)
print(f'Test Loss: {score[0]}')
print(f'Test Accuracy: {score[1]}')
```

